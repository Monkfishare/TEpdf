<html lang="en"><meta name="viewport" content="width=device-width, initial-scale=1" /><head><link rel="stylesheet" href="../init.css"></head><body><section class="css-qm1vln e1m3q8rc0"><div class="css-b4a1pi elvs37n0"><span class="css-1te5c83 e11l78dl0"><a data-analytics="sidebar:section" href="/business/"><span>Business</span></a></span><span class="css-1mdqtqm e11bnqe00"> | <!-- -->OpenAI v CloseAI</span></div><h1 class="css-fk78xg e1t4u3eq0">Sam Altman’s return marks a new phase for OpenAI </h1><h2 class="css-o55d57 elmr55g0">The industry seems set to move from academic idealism to commercial pragmatism </h2></section><img id="myImg" src="../image/20231125_WBD002.jpg" width="auto" height="200"><section class="css-1fpllpa ee5d8yd1" data-body-id="cp2"><div class="css-knmu16 ee5d8yd2"><p class="css-1hno3qs e190yofl0" data-component="paragraph"><span data-caps="initial">E</span><small>VEN BY TECH’S</small> fast-moving standards,  the past week in the world of artificial intelligence (<small>AI</small>) was head-spinning. On November 17th the board of Open<small>AI</small> booted out Sam Altman, the Chat<small>GPT</small>-maker’s boss. By November 20th Mr Altman had been offered refuge at Microsoft, the startup’s biggest backer. The same day nearly all of Open<small>AI</small>’s 770 employees signed a letter threatening to quit unless the board members who dismissed Mr Altman reinstate him and resign. On November 21st Mr Altman was back in his old job. Heads have, then, spun back more or less to where they started. Or have they?</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">In fact, the Open<small>AI</small> saga marks the start of a new, more grown-up phase for the <small>AI</small> industry. For Open<small>AI</small>, Mr Altman’s triumphant return may supercharge its ambitions. For Microsoft, which stood by Mr Altman in his hour of need, the episode may result in greater sway over <small>AI</small>’s hottest startup. For <small>AI</small> companies everywhere it may herald a broader shift away from academic idealism and towards greater commercial pragmatism. And for the technology’s users, it may, with luck, usher in more competition and more choice.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-1"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">To understand all these implications, start with what happened. Open<small>AI</small>’s board fired Mr Altman for not being “consistently candid in his communications’‘. One factor that may have influenced the decision was disagreement over whether Open<small>AI</small> had struck the right balance between the speed and safety of its products. Insiders say that Open<small>AI</small> had made a breakthrough that enabled models to get better at solving problems without additional data. This spooked Ilya Sutskever, a co-founder and board member. Helen Toner, a board member affiliated with Georgetown University, had published an academic article that laid out what she saw as flaws in Open<small>AI</small>’s approach to <small>AI</small> safety. On November 21st the <i>New York Times</i> reported that Mr Altman, worried about the negative press, had moved to oust Ms Toner. There were also concerns over Mr Altman’s side-projects, including a planned <small>AI</small>-semiconductor venture that sent him to the Persian Gulf to court billions in Saudi money.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">In the end it was Ms Toner and three other board members that ousted him instead. The sixth director, Greg Brockman, was also stripped of his board seat and then quit in solidarity with Mr Altman. The two of them found succour at Microsoft, which said it would create a new in-house <small>AI</small> lab which they would run. Microsoft also pledged to hire the rest of Open<small>AI</small>’s team. Whether or not this was ever a serious plan may never be known. But it lent Mr Altman huge bargaining power when negotiating his return to Open<small>AI</small>. On November 20th, as those negotiations were under way, Satya Nadella, the tech giant’s chief executive, declared that “Irrespective of where Sam is, he’s working with Microsoft.”</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">The deal struck by Mr Altman and those who ousted him will transform Open<small>AI</small>, starting with the board. Ms Toner and Mr Sutskever are out. So is Tasha McCauley, a tech entrepreneur. All three backed Mr Altman’s dismissal. Mr Brockman and, for the time being, Mr Altman will not be returning. Of the pre-chaos six only Adam D’Angelo, the founder of Quora, a question-and-answer site, stays on. He will be joined by heavyweights, starting with Bret Taylor, a former co-<small>CEO</small> of Salesforce, another big software firm, and Larry Summers of Harvard University, who served as Bill Clinton’s treasury secretary. The <i>Verge</i>, an online publication, has reported that the new board will aim to expand to nine members; Microsoft is expected to get a seat and Mr Altman may get his back.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-2"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">The new directors are likely to make <a href="https://www.economist.com/business/2023/11/21/inside-openais-weird-governance-structure">Open<small>AI</small></a>, which is structured as a for-profit entity within a non-profit one, more business-minded. Mr Taylor and Mr Summers are well-regarded figures with plenty of boardroom experience. Their views on <small>AI</small> safety are not known. But they may be more receptive than Ms Toner and Ms McCauley to Mr Altman’s empire-building ambitions. The same already seems to be true of Open<small>AI</small>’s workforce. One employee reports that the startup’s staff, which “trauma-bonded” during the upheaval, will become even more loyal to Mr Altman and, possibly, readier to pursue his commercial vision. Work on the firm’s most powerful model yet, <small>GPT</small>-5, which appeared to have slowed for a few months, will now probably go full speed ahead.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">The sour taste left by the imbroglio may nevertheless linger. It was not, in the words of a prominent <small>AI</small> investor, a “confidence-inducing event”. That is putting it mildly. On the morning of November 17th Open<small>AI</small> was poised to close a tender offer led by Thrive Capital, a venture-capital firm, that would value the startup at $86bn. The offer was suspended. Though it is reportedly back on, investors in the secondary market for startup shares remain cautious. Worse, if Mr Altman and Mr Sutskever do not reconcile, Open<small>AI</small> could lose one of the world’s most respected <small>AI</small> minds.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Microsoft’s fortunes look more secure. Whereas Open<small>AI</small>’s brand has taken a hit, Microsoft’s has not. The software giant probably prefers having Open<small>AI</small> at arm’s length rather than Mr Altman and his boffins close to its chest. By temperament, Mr Altman and Mr Brockman are not a natural fit for one of the world’s biggest companies; many observers doubted that either would have stayed at Microsoft for long.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Recreating Open<small>AI</small> in-house would also have slowed the progress of the technology in the short term, argues Mark Moerdler of Bernstein, a broker. Many Open<small>AI</small> employees said in private that they would rather move to a different firm than Microsoft, even though they signed the petition threatening to follow Mr Altman there. Mr Nadella did not seem terribly disappointed with the outcome. Microsoft’s share price, which dipped by 2% on the news of Mr Altman’s sacking, has clawed back all those losses. On November 22nd its market value reached an all-time high of $2.8trn.</p><div class="css-1bzwzkr eitqf4z1"><figure class="css-qts40t e1197rjj0"><img data-nimg="1" decoding="async" height="740" loading="lazy" sizes="300px" src="../image/20231125_WBC479.png" srcset="../image/20231125_WBC479.png" style="color:transparent" width="608"/><figcaption class="css-18w36g1 edweubf2"><span class="css-6pzdis edweubf1">image: The Economist</span></figcaption></figure></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">What about the rest of the <small>AI</small> industry? Open<small>AI</small> is the undisputed leader in the <small>AI</small> race (see chart). A survey by Retool, a startup, found that 80% of software developers said that they used Open<small>AI</small>’s models more often than those of rival model-makers. Chat<small>GPT</small>, a chatty app whose launch one year ago turned Open<small>AI</small> into a household name, receives 60% of web traffic to the top 50 websites for such “generative” <small>AI</small>. In October the firm was earning revenues at an annualised rate of $1.3bn.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Even if Open<small>AI</small> moves faster under new leadership, it will face more competition. An <small>AI</small>-focused venture capitalist likens the moment to the implosion earlier this year of Silicon Valley Bank, which taught many startups not to put all their eggs in one basket. As the Altman drama was unfolding, more than 100 Open<small>AI</small> customers contacted Anthropic, a rival model-maker, according to the <i>Information</i>, an online publication. Some tapped Cohere, another startup, and the cloud unit of Google, which has invested in Anthropic. The cloud arm of Amazon, another Anthropic-backer, set up a team to work with switchers.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-3"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">The events at Open<small>AI</small> are a dramatic manifestation of a wider divide in Silicon Valley. On one side are the “doomers”, who believe that, left unchecked, <small>AI</small> poses an existential risk to humanity and hence advocate stricter regulations. Opposing them are “boomers”, who play down fears of an <small>ai</small> apocalypse and stress its potential to turbocharge progress. The split reflects in part philosophical differences. Many in the doomer camp are influenced by “effective altruism”, a movement worried that <small>Ai</small> might wipe out humanity. Boomers espouse a worldview called “effective accelerationism”, which counters that the development of <small>AI</small> should be speeded up.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Mr Altman seemed to have sympathy with both groups, publicly calling for “guardrails” to make <small>ai</small> safe while pushing Open<small>ai</small> to develop more powerful models and launching new tools, such as an app store for users to build their own chatbots. Today he looks decidedly more boomerish, as do the majority of Open<small>AI</small>’s workers who wanted him back. The doomers are on the back foot.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">That will worry politicians, who are scrambling to show that they take the risks seriously. In July President Joe Biden’s administration nudged seven leading model-makers, including Google, Meta, Microsoft and Open<small>ai</small>, to make “voluntary commitments” to have their <small>ai</small> products inspected by experts before releasing them to the public. On November 1st the British government got a similar group to sign another non-binding agreement that allowed regulators to test their <small>ai</small>s for trustworthiness and harmful capabilities, such as endangering national security.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Days earlier Mr Biden issued an executive order with more bite. It compels any <small>ai</small> firm building models above a certain size—defined by the computing power required—to notify the government and share its safety-testing results. As boomers gain the upper hand in Silicon Valley, the White House’s model-inspectors should expect to have their hands full. <span class="ufinish">■</span></p><p class="css-1hno3qs e190yofl0" data-component="paragraph"><i>Read more of our articles on <a href="https://www.economist.com/artificial-intelligence">artificial intelligence</a></i></p><p class="css-1hno3qs e190yofl0" data-component="paragraph"><i>To stay on top of the biggest stories in business and technology, sign up to the <a href="https://www.economist.com/newsletters/the-bottom-line">Bottom Line</a>, our weekly subscriber-only newsletter.</i></p></div></section></body>
    <script>
    window.tedl = window.tedl || {};
    // Resize iframes on articles with interactives when they send a RESIZE message
    window.addEventListener('message', (event) => {
    if (event.data.type === 'RESIZE') {
    Array.prototype.forEach.call(document.getElementsByTagName('iframe'), function (element) {
    if (element.contentWindow === event.source) {
    const height = parseInt(event.data.payload.height, 10);
    const elementHeight = parseInt(element.style.height, 10);
    if (isNaN(elementHeight) | Math.abs(elementHeight - height) > 10){
        element.style.height = height + 'px';
    }
    // 
    console.log(elementHeight - height);
    }
    });
    }
    }, false);
    </script>
    </html>