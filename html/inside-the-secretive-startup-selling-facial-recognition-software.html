<html lang="en"><meta name="viewport" content="width=device-width, initial-scale=1" /><head><link rel="stylesheet" href="../init.css"></head><body><section class="css-qm1vln e1m3q8rc0"><div class="css-b4a1pi elvs37n0"><span class="css-1te5c83 e11l78dl0"><a data-analytics="sidebar:section" href="/culture/"><span>Culture</span></a></span><span class="css-1mdqtqm e11bnqe00"> | <!-- -->Surveillance, Inc.</span></div><h1 class="css-fk78xg e1t4u3eq0">Inside the secretive startup selling facial-recognition software</h1><h2 class="css-o55d57 elmr55g0">In “Your Face Belongs to Us” Kashmir Hill profiles Clearview AI</h2></section><img id="myImg" src="../image/20231104_CUD002.jpg" width="auto" height="200"><section class="css-12k3cm0 e1ey6m751" data-body-id="cp2"><div class="css-1746s8a e1ey6m752"><p class="css-14046qw e1xfd4x10"><b>Your Face Belongs to Us. </b>By Kashmir Hill.<i> Random House; 352 pages; $28.99.  Simon &amp; Schuster; £20</i></p><p class="css-1hno3qs e190yofl0" data-component="paragraph"><span data-caps="initial">M</span><small>ost people </small>expect to walk down a street anonymously. Passersby do not know fellow pedestrians’ names, jobs or what they just posted online. But owing to the <a href="https://www.economist.com/leaders/2017/09/09/what-machines-can-tell-from-your-face">growth of facial-recognition technology</a>, norms around privacy are being eroded, Kashmir Hill, a journalist for the <i>New York Times</i>,<i> </i>argues in a new book. Software enables people’s photos to be instantly matched to online images and digital profiles. This type of technology is now popular among <a href="https://www.economist.com/united-states/2019/05/25/america-is-turning-against-facial-recognition-software">law-enforcement agencies</a>. </p><p class="css-1hno3qs e190yofl0" data-component="paragraph">The technology began in the 1960s. With funding from the <small>CIA</small>, researchers built a system to match faces photographed at different angles. By the 1980s, experts could configure a face as a mathematical calculation based on how it differed from the average face. As computers became more powerful, the technology grew more useful. In 2001 police scanned Super Bowl attendees’ faces in Tampa and compared them to a database of known criminals. (The event was nicknamed <a href="https://www.economist.com/united-states/2001/09/20/uncle-sam-and-the-watching-eye">“Snooper Bowl”</a>.) Big tech firms, including Google and Facebook, developed face-scanning systems but stopped short of releasing tools to others for fear of abuse.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-1"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">Hoan Ton-That, co-founder of Clearview <small>AI</small>, a secretive startup, had no such qualms. At the age of 19 the Australian university drop-out moved to Silicon Valley. He built a video-streaming site, which  automatically emailed marketing material to users’ contacts. He then moved to New York, where he met Richard Schwartz, who had worked as an adviser to Rudy Giuliani, the former mayor of New York. The pair hit it off and founded Clearview <small>AI</small>. Along the way they were helped by a cast of right-wing characters, such as Peter Thiel, who put money in Clearview.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">While Mr Schwartz provided connections, Mr Ton-That built the app. With the help of a friend, he designed an advanced face-matching algorithm. Relying on a database of harvested images of people’s faces from popular websites, such as Facebook, the app managed to link people’s photos to their personal details. Much of the web scraping was done by contractors, some of whom used fake names and were paid in cryptocurrency. Eventually Clearview’s database grew to 30bn photos.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Venture capitalists were given free trials, as Clearview wooed them. (Some used it as a party trick, others to recognise acquaintances at conferences.) But Clearview found most success with law enforcement. Police teams often had databases of mugshots, which only contained people who had been arrested. The app helped investigators match faces from surveillance footage with online profiles. By mid-2019, more than 200 law-enforcement agencies had used the tool, including the <small>FBI </small>and counterparts abroad. Among police, the app became a verb. “We Clearviewed the guy and then passed the information along to the right unit,” one officer told Ms Hill.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Mostly the app is highly accurate. But misidentification has also led to wrongful arrests. This problem is most prevalent <a href="https://www.economist.com/science-and-technology/2018/02/17/computer-programs-recognise-white-men-better-than-black-women">among minorities</a>, who are underrepresented in the databases used to teach the algorithm how to match faces.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-2"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">Much of Clearview’s rise went on in secret. That changed when Ms Hill received a tip-off and doggedly investigated the company, publishing a front-page story in 2020. The press coverage triggered lawsuits and <a href="https://www.economist.com/united-states/2021/03/09/america-grapples-with-regulating-surveillance-technology">regulatory probes</a>, which concluded that the firm must obtain consent from people whose images it uses. Clearview’s app was banned in at least six countries. As part of one legal settlement, the firm agreed not to sell its software to individuals and private companies in America, though it still sells to law enforcement.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">One shortcoming of this gripping book is that it only lightly touches on <a href="https://www.economist.com/culture/2022/09/22/in-china-surveillance-crushes-lives-and-improves-them">China</a> and Russia, where the abuses of facial-recognition technology are most abhorrent. Another is that the author makes little effort to try to weigh the benefits of facial recognition (catching more criminals) against the disadvantages (an erosion of privacy).</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Nevertheless, the book is illuminating. The scope and sophistication of the technology is striking. So, too, is the way in which the building blocks needed to make it are so readily available, from open-source code to public databases of faces. A walk down the street will not feel quite the same again. <span class="ufinish">■</span></p><p class="css-1hno3qs e190yofl0" data-component="paragraph"><i>For more on the latest books, films, <small>TV </small>shows, albums and controversies, sign up to <a href="https://www.economist.com/culture/2022/11/23/introducing-plot-twist-our-new-culture-newsletter" target="_blank">Plot Twist</a>, our weekly subscriber-only newsletter</i></p></div></section></body>
    <script>
    window.tedl = window.tedl || {};
    // Resize iframes on articles with interactives when they send a RESIZE message
    window.addEventListener('message', (event) => {
    if (event.data.type === 'RESIZE') {
    Array.prototype.forEach.call(document.getElementsByTagName('iframe'), function (element) {
    if (element.contentWindow === event.source) {
    const height = parseInt(event.data.payload.height, 10);
    const elementHeight = parseInt(element.style.height, 10);
    if (isNaN(elementHeight) | Math.abs(elementHeight - height) > 10){
        element.style.height = height + 'px';
    }
    // 
    console.log(elementHeight - height);
    }
    });
    }
    }, false);
    </script>
    </html>