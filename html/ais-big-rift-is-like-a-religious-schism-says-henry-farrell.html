<html lang="en"><meta name="viewport" content="width=device-width, initial-scale=1" /><head><link rel="stylesheet" href="../init.css"></head><body><section class="css-qm1vln e1m3q8rc0"><div class="css-b4a1pi e1u9wqfn0"><span class="css-1te5c83 e11l78dl0"><a data-analytics="sidebar:section" href="/by-invitation/"><span>By Invitation</span></a></span><span class="css-1mdqtqm e11bnqe00"> | <!-- -->Artificial intelligence</span></div><h1 class="css-6p5r16 e11fb5bd0">AI’s big rift is like a religious schism, says Henry Farrell</h1><h2 class="css-o55d57 elmr55g0">In this doctrinal dust-up, very smart people are saying very strange things</h2></section><img id="myImg" src="../image/20231216_BID001.jpg" width="auto" height="200"><section class="css-1fpllpa ee5d8yd1" data-body-id="cp2"><div class="css-1qkdneh ee5d8yd2"><p class="css-1hno3qs e190yofl0" data-component="paragraph"><span data-caps="initial">T</span><small>WO CENTURIES</small> ago Henri de Saint-Simon, a French utopian, proposed a new religion, worshipping the godlike force of progress, with Isaac Newton as its chief saint. He believed that humanity’s sole uniting interest, “the progress of the sciences”, should be directed by the “elect of humanity”, a 21-member “Council of Newton”. Friedrich Hayek, a 20th-century economist, later gleefully described how this ludicrous “religion of the engineers” collapsed into a welter of feuding sects.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Today, the engineers of artificial intelligence (<small>AI</small>) are experiencing their own religious schism. One sect worships progress, canonising Hayek himself. The other is gripped by terror of godlike forces. Their battle has driven practical questions to the margins of debate.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-1"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">Both cults are accidental by-products of science fiction. In 1993 Vernor Vinge drew on computer science and his fellow science-fiction writers to argue that ordinary human history was drawing to a close. We would surely create superhuman intelligence sometime within the next three decades, leading to a “Singularity”, in which <small>AI</small> would start feeding on itself. The future might be delightful or awful, depending on whether machines enhanced human intelligence or displaced it.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Some were optimistic. The futurist Ray Kurzweil wrote an enormous tome, “The Singularity is Near”, predicting a cusp in 2045. We humans would become immortal, spreading intelligence throughout the universe, and eventually merging into God. For all its statistics and exponentials, the book prophesied “the Rapture of the Nerds”, as one unkind critic called it. Its title really should have been “The Singularity is Nigh”.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Others feared the day of judgment. Eliezer Yudkowsky, a self-taught <small>AI</small> researcher, was deeply influenced by Mr Vinge’s ideas. He fathered Silicon Valley’s “rationalist” movement, which sought to improve human reasoning and stop <small>AI</small> destroying humankind.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Rationalists believed that Bayesian statistics and decision theory could de-bias human thinking and model the behaviour of godlike intelligences. They revelled in endless theoretical debates, like medieval Christian philosophers disputing the nature of angels, applying amateur game theory instead of Aristotelian logic. Sometimes their discussions were less erudite. Mr Yudkowsky popularised his ideas in a 660,000-word fan-fiction epic, “Harry Potter and the Methods of Rationality”.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Rationalists feared that superhuman <small>AI</small>s wouldn’t have our best interests at heart. One notorious thought experiment—a modern version of Pascal’s wager, dubbed “Roko’s basilisk”—claimed that logic dictated that future divine intelligences would torture anyone who had known that <small>AI</small> was possible and hadn’t devoted themselves to bringing it into existence. <small>AI</small>s might also use their awesome reasoning powers to escape any limits that humans imposed on them, creating an “x risk” (existential risk) to human survival.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-2"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">Rationalism explains why <small>AI</small> pioneers became obsessed with x risk. Sam Altman, Elon Musk and others founded Open<small>AI</small>, the creator of Chat<small>GPT</small>, as a non-profit so that it wouldn’t duck the dangers of machine intelligence. But the incentives shifted as the funding flooded in. Some Open<small>AI</small> staffers feared that their employer cared more about the opportunities than the dangers and defected to found Anthropic, a rival <small>AI</small> firm. More recently, clashes over <small>AI</small> risk, money and power reportedly led to the fracture between Mr Altman and his board.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">If rationalists are frustrated by Silicon Valley’s profit model, Silicon Valley is increasingly frustrated by rationalism. Marc Andreessen, the co-founder of Andreessen Horowitz, a venture-capital firm, fulminated in June that the extremist <small>AI</small>-risk “cult” was holding back an awesome <small>AI</small>-augmented future, in which humanity could reach for the stars.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">This backlash is turning into its own religion of the engineers. Grimes, a musician and Silicon Valley icon, marvels that <small>AI</small> engineers are “designing the initial culture of the universe”. She calls for a “Council of Elrond” (this conclave a nod to “The Lord of the Rings”) comprising the “heads of key <small>AI</small> companies and others who understand it” to set <small>AI</small> policy. Grimes met Mr Musk, the father of her children, through a shared joke about Roko’s basilisk.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">In October Mr Andreessen published his own “Techno-Optimist Manifesto” to wide acclaim from Silicon Valley entrepreneurs. In it, he takes aim at a decades-long “demoralisation campaign…against technology and life”, under various names including “sustainable development goals”, “social responsibility”, “trust and safety” and “tech ethics”. Efforts to decelerate <small>AI</small> “will cost human lives” and are thus tantamount to “murder”.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Mr Andreessen’s manifesto is a Nicene creed for the cult of progress: the words “we believe” appear no less than 113 times in the text. His list of the “patron saints” of techno-optimism begins with Based Beff Jezos, the social-media persona of a former Google engineer who claims to have founded “effective accelerationism”, a self-described “meta-religion” which puts its faith in the “technocapital Singularity”.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">Our future is currently being built around Mr Vinge’s three-decades-old essay, a work that only Silicon Valley thinkers and science-fiction fans have read. Warring cults dispute whether engineers are as gods, or just unwitting Dr Frankensteins.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">This schism is an attention-sucking black hole that makes its protagonists more likely to say and perhaps believe stupid things. Of course, many <small>AI</small>-risk people recognise that there are problems other than the Singularity, but it’s hard to resist its relentless gravitational pull. Before Mr Andreessen was fully dragged past the event horizon, he made more nuanced arguments about engineers’ humility and addressing the problems of <small>AI</small> as they arose.</p><p class="css-1hno3qs e190yofl0" data-component="paragraph">But we need even more to listen to other people. Last month, at Rishi Sunak’s global <small>AI</small>-policy summit, Mr Musk pontificated about the need for an “off switch” for hostile <small>AI</small>. The main event was all about x risk and <small>AI</small>’s transformative promise, consigning other questions to a sideshow dubbed the “<small>AI</small> Fringe”.</p><div class="adComponent_advert__V79Pp adComponent_incontent__Bxd2J adComponent_hidden___o_ZB css-0 e1cbnkh80"><div><div class="adComponent_adcontainer__dO1Zm" id="econ-3"></div></div></div><p class="css-1hno3qs e190yofl0" data-component="paragraph">At the same time, Rachel Coldicutt, a British tech thinker, was putting together a “Fringe of the Fringe”, where a much more diverse group of thinkers debated the topics that hadn’t made the main agenda: communities, transparency, power. They didn’t suggest a Council of the Elect. Instead, they proposed that we should “make <small>AI</small> work for eight billion people, not eight billionaires”. It might be nice to hear from some of those 8bn voices.<span class="ufinish">■</span></p><p class="css-1hno3qs e190yofl0" data-component="paragraph"><i>Henry Farrell is a professor of international affairs and democracy at Johns Hopkins University, and co-author of “Underground Empire: How America Weaponized the World Economy”</i>.</p></div></section></body>
    <script>
    window.tedl = window.tedl || {};
    // Resize iframes on articles with interactives when they send a RESIZE message
    window.addEventListener('message', (event) => {
    if (event.data.type === 'RESIZE') {
    Array.prototype.forEach.call(document.getElementsByTagName('iframe'), function (element) {
    if (element.contentWindow === event.source) {
    const height = parseInt(event.data.payload.height, 10);
    const elementHeight = parseInt(element.style.height, 10);
    if (isNaN(elementHeight) | Math.abs(elementHeight - height) > 10){
        element.style.height = height + 'px';
    }
    // 
    console.log(elementHeight - height);
    }
    });
    }
    }, false);
    </script>
    </html>